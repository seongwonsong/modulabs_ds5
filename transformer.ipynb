{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1a3591db",
        "miOt4NTS-kkx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 2. 데이터 전처리하기  \n",
        "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다.  \n",
        "\n",
        "Step 3. SubwordTextEncoder 사용하기  \n",
        "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요.  \n",
        "\n",
        "Step 4. 모델 구성하기  \n",
        "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다.  \n",
        "\n",
        "Step 5. 모델 평가하기  \n",
        "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
      ],
      "metadata": {
        "id": "suGTCNrwW-Zm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a3591db"
      },
      "source": [
        "# 한국어 챗봇 모델 구축\n",
        "\n",
        "## Step 1. 데이터 준비\n",
        "\n",
        "원본 데이터셋 (`ChatbotData.csv`)을 사용하여 한국어 챗봇 모델을 구축합니다.\n",
        "\n",
        "## Step 2. 데이터 전처리\n",
        "\n",
        "한국어 데이터에 맞게 전처리 함수를 정의하고 질문-답변 쌍 데이터셋을 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c719449d",
        "outputId": "9a0b3afc-9589-44fa-c1ed-8830dc3e6107"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거 - 한국어에는 소문자 변환이 크게 의미 없을 수 있지만, 일관성을 위해 유지\n",
        "  sentence = str(sentence).lower().strip() # Ensure input is string and lower case (for consistency)\n",
        "\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  # 한국어 구두점 및 특수문자 처리 강화\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  # 한글, 영어 알파벳, 숫자, 그리고 기본적인 구두점(., ?, !, ,)만 남기고 모두 공백으로 대체\n",
        "  sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence\n",
        "\n",
        "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
        "def load_conversations():\n",
        "  inputs, outputs = [], []\n",
        "  with open('ChatbotData.csv', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "    # Skip the header row and handle potential empty lines or malformed rows\n",
        "    for line in lines[1:]:\n",
        "      parts = line.strip().split(',')\n",
        "      # Ensure there are at least 3 columns and the question and answer are not empty\n",
        "      if len(parts) >= 3 and parts[1].strip() and parts[2].strip():\n",
        "        inputs.append(preprocess_sentence(parts[1]))\n",
        "        outputs.append(preprocess_sentence(parts[2]))\n",
        "\n",
        "        # Use a reasonable MAX_SAMPLES if defined, otherwise load all\n",
        "        if 'MAX_SAMPLES' in globals() and len(inputs) >= MAX_SAMPLES:\n",
        "            return inputs, outputs\n",
        "  return inputs, outputs\n",
        "\n",
        "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
        "questions, answers = load_conversations()\n",
        "print('전체 샘플 수 :', len(questions))\n",
        "print('전체 샘플 수 :', len(answers))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수 : 11819\n",
            "전체 샘플 수 : 11819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746bf13d"
      },
      "source": [
        "## Step 3. SubwordTextEncoder 사용하기\n",
        "\n",
        "형태소 분석기 대신 SubwordTextEncoder를 사용하여 한국어 데이터를 토크나이징합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76473cd3",
        "outputId": "77839cc0-a024-44d0-c50d-5d75f6a8e80d"
      },
      "source": [
        "# 사용할 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "print(\"SubwordTextEncoder를 사용하여 Vocabulary를 생성합니다.\")\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
        "# target_vocab_size를 사용하여 단어장의 크기를 제한할 수 있습니다.\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print('단어장의 크기 :', (VOCAB_SIZE))\n",
        "\n",
        "\n",
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    # SubwordTextEncoder의 encode는 이미 [UNK] 토큰 처리를 포함합니다.\n",
        "    sentence1_encoded = [START_TOKEN[0]] + tokenizer.encode(sentence1) + [END_TOKEN[0]]\n",
        "    sentence2_encoded = [START_TOKEN[0]] + tokenizer.encode(sentence2) + [END_TOKEN[0]]\n",
        "\n",
        "    # 최대 길이 MAX_LENGTH 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1_encoded) <= MAX_LENGTH and len(sentence2_encoded) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1_encoded)\n",
        "      tokenized_outputs.append(sentence2_encoded)\n",
        "\n",
        "  # 최대 길이 MAX_LENGTH로 모든 데이터셋을 패딩\n",
        "  # padding='post'는 시퀀스 뒤에 0을 채웁니다.\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post', value=0) # Explicitly set padding value to 0\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post', value=0) # Explicitly set padding value to 0\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "questions_tokenized, answers_tokenized = tokenize_and_filter(questions, answers)\n",
        "\n",
        "print('필터링 및 토큰화 후 질문 샘플 개수: {}'.format(len(questions_tokenized)))\n",
        "print('필터링 및 토큰화 후 답변 샘플 개수: {}'.format(len(answers_tokenized)))\n",
        "\n",
        "# tf.data.Dataset 구성 (튜플 구조 사용)\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    (questions_tokenized, answers_tokenized[:, :-1]), # Inputs tuple: (inputs, dec_inputs)\n",
        "    answers_tokenized[:, 1:]                          # Outputs tensor\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(\"\\nDataset 구성 완료 (튜플 구조).\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SubwordTextEncoder를 사용하여 Vocabulary를 생성합니다.\n",
            "단어장의 크기 : 7936\n",
            "필터링 및 토큰화 후 질문 샘플 개수: 11819\n",
            "필터링 및 토큰화 후 답변 샘플 개수: 11819\n",
            "\n",
            "Dataset 구성 완료 (튜플 구조).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fc97437"
      },
      "source": [
        "## Step 4. 모델 구성하기\n",
        "\n",
        "트랜스포머 모델을 구현합니다. 인코더와 디코더 구조를 포함합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "e2f47bbd",
        "outputId": "20bd7ae4-ba2d-4ffd-bab2-f5994453c31d"
      },
      "source": [
        "# Positional Encoding Layer\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(tf.cast(10000, tf.float32), (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0])\n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Explicitly convert to dense tensor and cast to float32\n",
        "    inputs = tf.cast(tf.sparse.to_dense(inputs) if isinstance(inputs, tf.SparseTensor) else inputs, tf.float32)\n",
        "    # Dynamically slice positional encoding based on input shape\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "# 패딩 마스크 생성 함수\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "# 룩어헤드 마스크 생성 함수\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "# 인코더 레이어 함수\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "# 인코더 함수\n",
        "def encoder(\n",
        "            vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\", dtype=tf.int32)\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\", dtype=tf.float32)\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model, dtype=tf.float32)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "# 디코더 레이어 함수\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "\n",
        "# 디코더 함수\n",
        "def decoder(\n",
        "            vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs', dtype=tf.int32)\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs', dtype=tf.float32)\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask', dtype=tf.float32)\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask', dtype=tf.float32)\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model, dtype=tf.float32)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "\n",
        "# 트랜스포머 모델 함수\n",
        "def transformer(\n",
        "                vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\", dtype=tf.int32)\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\", dtype=tf.int32)\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask', dtype=tf.float32)(inputs)\n",
        "\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask', dtype=tf.float32)(dec_inputs)\n",
        "\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask', dtype=tf.float32)(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\", dtype=tf.float32)(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 모델 생성\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ enc_padding_mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,085,824\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ enc_padding_mask… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ look_ahead_mask     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_padding_mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;45mNone\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,613,184\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ look_ahead_mask[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ dec_padding_mask… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ outputs (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m2,039,552\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                     │ \u001b[38;5;34m7936\u001b[0m)             │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ enc_padding_mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,085,824</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ enc_padding_mask… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ look_ahead_mask     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dec_padding_mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,613,184</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ look_ahead_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ dec_padding_mask… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,039,552</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">7936</span>)             │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,738,560\u001b[0m (33.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,738,560</span> (33.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,738,560\u001b[0m (33.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,738,560</span> (33.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a20623a"
      },
      "source": [
        "## Step 5. 모델 평가 및 추론 함수\n",
        "\n",
        "학습된 모델을 사용하여 입력 문장에 대한 답변을 생성하는 함수를 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "9b5d36f4",
        "outputId": "3297cc76-aa80-4d20-ddf6-500694db6b82"
      },
      "source": [
        "# 예측(인퍼런스) 함수\n",
        "def decoder_inference(sentence, repetition_penalty=1.0):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장.\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # Keep track of generated token IDs in the current output sequence\n",
        "  generated_token_ids = set(tf.squeeze(output_sequence, axis=0).numpy())\n",
        "\n",
        "  # 디코더의 인퍼런스 단계 (최대 길이까지 반복)\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :] # 마지막 토큰에 대한 예측값만 가져오기\n",
        "\n",
        "    # Get the logits for the current step\n",
        "    logits = tf.squeeze(predictions, axis=0) # Shape: (1, vocab_size) -> (vocab_size,)\n",
        "\n",
        "    # Apply repetition penalty for already generated tokens in this output sequence\n",
        "    if repetition_penalty != 1.0:\n",
        "        # Create a mask for generated tokens\n",
        "        # Use tf.one_hot to create a one-hot representation of generated tokens\n",
        "        # Then sum along axis 0 to get a mask where generated tokens have a value > 0\n",
        "        # Cast the result to boolean\n",
        "        generated_mask = tf.cast(tf.reduce_sum(tf.one_hot(list(generated_token_ids), depth=VOCAB_SIZE), axis=0), dtype=tf.bool)\n",
        "\n",
        "        # Apply penalty: reduce logits for generated tokens\n",
        "        # Use multiplication in logit space\n",
        "        logits = tf.where(generated_mask, logits * repetition_penalty, logits)\n",
        "\n",
        "        # Alternative: Set logit to a large negative value multiplied by penalty (more aggressive)\n",
        "        # large_negative = -1e9\n",
        "        # logits = tf.where(generated_mask, large_negative * repetition_penalty, logits)\n",
        "\n",
        "\n",
        "    # Get the predicted token ID from the (potentially penalized) logits\n",
        "    predicted_id = tf.cast(tf.argmax(tf.expand_dims(logits, axis=0), axis=-1), tf.int32)\n",
        "\n",
        "    # If the predicted token is already in the generated set (and not an end token),\n",
        "    # apply a harsher penalty or resample. For simplicity here, we'll rely on the logit penalty.\n",
        "    # A more robust approach might involve resampling if the top prediction is a repeated token.\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # Add the predicted token ID to the set of generated tokens\n",
        "    # Ensure the predicted_id is a scalar integer before adding to the set\n",
        "    generated_token_ids.add(predicted_id.numpy().item())\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)\n",
        "\n",
        "# 답변 생성 함수 (uses the modified decoder_inference)\n",
        "def sentence_generation(sentence, repetition_penalty=1.0):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence, repetition_penalty)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  # 토큰화되지 않은 패딩 값(0)은 디코딩에서 제외합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "\n",
        "# 테스트 문장으로 답변 생성 확인\n",
        "test_sentences = [\n",
        "    \"오늘 기분이 어때?\",\n",
        "    \"배고파 죽겠어\",\n",
        "    \"심심해\",\n",
        "    \"내일 뭐 할까?\",\n",
        "    \"고마워\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    sentence_generation(sentence, repetition_penalty=1.9)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘 기분이 어때?\n",
            "출력 : 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 세상에서 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4189161714.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0msentence_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4189161714.py\u001b[0m in \u001b[0;36msentence_generation\u001b[0;34m(sentence, repetition_penalty)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msentence_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;31m# 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4189161714.py\u001b[0m in \u001b[0;36mdecoder_inference\u001b[0;34m(sentence, repetition_penalty)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# 디코더의 인퍼런스 단계 (최대 길이까지 반복)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 마지막 토큰에 대한 예측값만 가져오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_keras_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         outputs = self._run_through_graph(\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             operation_fn=lambda op: operation_fn(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/function.py\u001b[0m in \u001b[0;36m_run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;31m# Change the layout for the layer output if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0;31m# This is useful for relayout intermediate tensor in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   4019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, grad_a, grad_b, name)\u001b[0m\n\u001b[1;32m   3587\u001b[0m         )\n\u001b[1;32m   3588\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3589\u001b[0;31m         return gen_math_ops.batch_mat_mul_v2(\n\u001b[0m\u001b[1;32m   3590\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3591\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, grad_x, grad_y, name)\u001b[0m\n\u001b[1;32m   1637\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1640\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BatchMatMulV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \"grad_x\", grad_x, \"grad_y\", grad_y)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LMS"
      ],
      "metadata": {
        "id": "miOt4NTS-kkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "평가문항\t상세기준\n",
        "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\t공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
        "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\t구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
        "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\t한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다."
      ],
      "metadata": {
        "id": "0SdxjsM7Xslb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTrd9FsjW2OA",
        "outputId": "f1db7d2a-fc74-4b84-9757-ecc2e0380b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.16.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uGNZ65qeY-sv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(tf.cast(10000, tf.float32), (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0])\n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Ensure inputs are float32\n",
        "    inputs = tf.cast(inputs, tf.float32)\n",
        "    # Dynamically slice positional encoding based on input shape\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "id": "KyvLFsnbu7xW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pos_encoding = PositionalEncoding(50,512)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "vXiKXoaMu_zj",
        "outputId": "703df135-3379-4047-a927-afdce66e698b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output"
      ],
      "metadata": {
        "id": "0WPDmVjAvBgS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "SnIOA7xjvGEh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "UkbOTvkGvIGA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "id": "HBQC8WZivLgv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "qpZJ8D9qvO9R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # Positional Encoding\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "k9jw5Gl3vQlj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "_uoQ-p3-vRsQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # Positional Encoding\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "hnIVB_tXvTPo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 샘플의 최대 개수\n",
        "MAX_SAMPLES = 50000\n",
        "print(MAX_SAMPLES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDtiXTr8vVcr",
        "outputId": "67ef69a9-0f25-4107-c54f-af6fd3a65d9b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "  # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
        "  sentence = sentence.lower().strip()\n",
        "\n",
        "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "  # student와 온점 사이에 거리를 만듭니다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
        "  sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-히?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "XbLANHYIvWpP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
        "def load_conversations():\n",
        "  inputs, outputs = [], []\n",
        "  with open('ChatbotData.csv', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "    # Skip the header row\n",
        "    for line in lines[1:]: # Assuming the first row is a header\n",
        "      parts = line.strip().split(',') # Assuming comma separated values\n",
        "      # Assuming question is in the second column (index 1) and answer in the third (index 2)\n",
        "      if len(parts) >= 3 and parts[1] and parts[2]: # Ensure both question and answer exist and are not empty\n",
        "        inputs.append(preprocess_sentence(parts[1]))\n",
        "        outputs.append(preprocess_sentence(parts[2]))\n",
        "\n",
        "        if len(inputs) >= MAX_SAMPLES:\n",
        "          return inputs, outputs\n",
        "  return inputs, outputs"
      ],
      "metadata": {
        "id": "mow4SoW0vXkM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
        "questions, answers = load_conversations()\n",
        "print('전체 샘플 수 :', len(questions))\n",
        "print('전체 샘플 수 :', len(answers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9o-AxFyvZCk",
        "outputId": "d9687ce4-a923-4d5d-f4ab-51ddee4f2a8e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 수 : 11819\n",
            "전체 샘플 수 : 11819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
        "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmXRtqeEvZ8J",
        "outputId": "7542b2e8-f611-4ca2-e341-6e1c1c7bdbfb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후의 22번째 질문 샘플: 다음 달에는 더 절약해봐요 .\n",
            "전처리 후의 22번째 답변 샘플: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A16Saojvarm",
        "outputId": "06c9e582-0d7b-430b-f164-93323a218f06"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
      ],
      "metadata": {
        "id": "jQkkk0vgvhEo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDgDPHlJvh8R",
        "outputId": "9c611d37-85e5-4738-ea70-6c059d2cdcfa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START_TOKEN의 번호 : [7906]\n",
            "END_TOKEN의 번호 : [7907]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxAjKBOivipa",
        "outputId": "d2303952-e181-4135-ae2f-1369f48b2fb8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
        "# 각 토큰을 고유한 정수로 변환\n",
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zAKYgDXvjc_",
        "outputId": "03914e99-3046-46b5-fecf-de6b96ec53a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 21번째 질문 샘플: [810, 6873, 4, 4685, 1]\n",
            "정수 인코딩 후의 21번째 답변 샘플: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 40\n",
        "print(MAX_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86lACaHDvkdy",
        "outputId": "d1adc81d-410e-4ae7-bea7-2d30d096d6fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "metadata": {
        "id": "7D75ORDBvlJ9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGZfBoKWvl6P",
        "outputId": "d925bdb3-b913-4f7d-f95b-fcc31f8e6ddb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 7908\n",
            "필터링 후의 질문 샘플 개수: 11819\n",
            "필터링 후의 답변 샘플 개수: 11819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "yZxbtbIkvms-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "xg6DDpJEvoGk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수\n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "cnFOMzDGvpPQ",
        "outputId": "3de97791-f4ba-4bc8-d098-1fa79feb7dad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Exception encountered when calling PositionalEncoding.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'positional_encoding' (of type PositionalEncoding). Either the `PositionalEncoding.call()` method is incorrect, or you need to implement the `PositionalEncoding.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nExpected float32, but got SparseTensor(indices=Tensor(\"Placeholder_1:0\", shape=(None, 3), dtype=int64), values=Tensor(\"Placeholder:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"PlaceholderWithDefault:0\", shape=(3,), dtype=int64)) of type 'SparseTensor'.\u001b[0m\n\nArguments received by PositionalEncoding.call():\n  • args=('<KerasTensor shape=(None, None, 256), dtype=float32, sparse=True, ragged=False, name=keras_tensor_4>',)\n  • kwargs=<class 'inspect._empty'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2008223052.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mDROPOUT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;31m# 드롭아웃의 비율\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m model = transformer(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-620627197.py\u001b[0m in \u001b[0;36mtransformer\u001b[0;34m(vocab_size, num_layers, units, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;31m# 인코더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   enc_outputs = encoder(\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1987658127.py\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(vocab_size, num_layers, units, d_model, num_heads, dropout, name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Positional Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3095422827.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Dynamically slice positional encoding based on input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling PositionalEncoding.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'positional_encoding' (of type PositionalEncoding). Either the `PositionalEncoding.call()` method is incorrect, or you need to implement the `PositionalEncoding.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nExpected float32, but got SparseTensor(indices=Tensor(\"Placeholder_1:0\", shape=(None, 3), dtype=int64), values=Tensor(\"Placeholder:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"PlaceholderWithDefault:0\", shape=(3,), dtype=int64)) of type 'SparseTensor'.\u001b[0m\n\nArguments received by PositionalEncoding.call():\n  • args=('<KerasTensor shape=(None, None, 256), dtype=float32, sparse=True, ragged=False, name=keras_tensor_4>',)\n  • kwargs=<class 'inspect._empty'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "mdq7XEG4vqMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "eXo3Uut_vq8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "metadata": {
        "id": "tsm0uv0cvrzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "xVZiIzUcvstK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "id": "-QkDqN3nvteW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)"
      ],
      "metadata": {
        "id": "OTyOn6Szvua7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "metadata": {
        "id": "fGacm10Lvvqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cm8pyYUSvwla"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}